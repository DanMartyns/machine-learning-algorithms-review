<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="https://gmpg.org/xfn/11" rel="profile" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta http-equiv="content-type" content="text/html; charset=utf-8" />

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1" />

  <title>
    
      Lasso vs Ridge Regression &middot; ML Algorithms Review
    
  </title>

  


  <!-- CSS -->
  <link rel="stylesheet" href="/machine-learning-algorithms-review/assets/css/main.css" />
  

<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Abril+Fatface" />

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/machine-learning-algorithms-review/favicon.png" />
<link rel="shortcut icon" href="/machine-learning-algorithms-review/favicon.ico" />

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/machine-learning-algorithms-review/feed.xml" />

  <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  <!-- Additional head bits without overriding original head -->
</head>


  <body class="post">

    <div id="sidebar">
  <header>
    <img src="http://localhost:4000//machine-learning-algorithms-review/favicon.png" />
    <div class="site-title">
      <a href="/machine-learning-algorithms-review/">
        
          <span class="back-arrow icon"><svg fill="#000000" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
  <path d="M0 0h24v24H0z" fill="none"/>
  <path d="M20 11H7.83l5.59-5.59L12 4l-8 8 8 8 1.41-1.41L7.83 13H20v-2z"/>
</svg></span>
        
      </a>
    </div>
    <p class="lead">Construction of a web page with a review of some Machine Learning algorithms.</p>
  </header>
  <nav id="sidebar-nav-links">
  
    <a class="home-link "
        href="/machine-learning-algorithms-review/">Home</a>
  
  

  

  


  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  

  
    
  

  
    
  

  

  
    
  


  


  
    
  

  
    
      <a class="category-link "
          href="/machine-learning-algorithms-review/category/MachineLearning.html">Machine Learning</a>
    
  

  
    
      <a class="category-link "
          href="/machine-learning-algorithms-review/category/SupervisedLearning.html">Supervised Learning</a>
    
  

  
    
  

  
    
  

  

  
    
  

  
    
  

  

  
    
  


  <!-- Optional additional links to insert in sidebar nav -->
</nav>


  

  <nav id="sidebar-icon-links">
  

  <a id="subscribe-link"
     class="icon" title="Subscribe" aria-label="Subscribe"
     href="/machine-learning-algorithms-review/feed.xml">
    <svg fill="#000000" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
    <path d="M0 0h24v24H0z" fill="none"/>
    <circle cx="6.18" cy="17.82" r="2.18"/>
    <path d="M4 4.44v2.83c7.03 0 12.73 5.7 12.73 12.73h2.83c0-8.59-6.97-15.56-15.56-15.56zm0 5.66v2.83c3.9 0 7.07 3.17 7.07 7.07h2.83c0-5.47-4.43-9.9-9.9-9.9z"/>
</svg>
  </a>

  
  
  
  

  
    <a id="tags-link"
       class="icon"
       title="Tags" aria-label="Tags"
       href="/machine-learning-algorithms-review/tags.html">
      <svg fill="#000000" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
    <path d="M0 0h24v24H0z" fill="none"/>
    <path d="M17.63 5.84C17.27 5.33 16.67 5 16 5L5 5.01C3.9 5.01 3 5.9 3 7v10c0 1.1.9 1.99 2 1.99L16 19c.67 0 1.27-.33 1.63-.84L22 12l-4.37-6.16z"/>
</svg>
    </a>
  

  <!-- 
    <a id="search-link"
       class="icon"
       title="Search" aria-label="Search"
       href="/machine-learning-algorithms-review/search.html">
      <svg fill="#000000" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
    <path d="M15.5 14h-.79l-.28-.27C15.41 12.59 16 11.11 16 9.5 16 5.91 13.09 3 9.5 3S3 5.91 3 9.5 5.91 16 9.5 16c1.61 0 3.09-.59 4.23-1.57l.27.28v.79l5 4.99L20.49 19l-4.99-5zm-6 0C7.01 14 5 11.99 5 9.5S7.01 5 9.5 5 14 7.01 14 9.5 11.99 14 9.5 14z"/>
    <path d="M0 0h24v24H0z" fill="none"/>
</svg>
    </a> -->
  

  <!-- Optional additional links to insert for icons links -->
</nav>

  <p>
  &copy; 2021.
  <a href="/machine-learning-algorithms-review/LICENSE.md">MIT License.</a>
</p>

</div>

    <main class="container">
      <header>
  <h1 class="post-title">Lasso vs Ridge Regression</h1>
</header>
<div class="content">
  <div class="post-meta">
  <span class="post-date">11 May 2021</span>
  <span class="post-categories">
    
      &bull;

      
      
      

      
        <a href="/machine-learning-algorithms-review/category/SupervisedLearning.html">
          Supervised Learning
        </a>
      
    
  </span>
</div>

  <div class="post-body">
    <p>In practice, ridge regression is usually the first choice between these two models. However, if you have a large amount of features and expect only a few of them to be important, Lasso might be a better choice. Similarly, if you would like to have a model that is easy to interpret, Lasso will provide a model that is easier to under‐ stand, as it will select only a subset of the input features. scikit-learn also provides the ElasticNet class, which combines the penalties of Lasso and Ridge. In practice, this combination works best, though at the price of having two parameters to adjust: one for the L1 regularization, and one for the L2 regularization.</p>

<h2 id="l1-regularization-vs-l2-regularization">L1 Regularization vs L2 Regularization</h2>

<p>In order to create a less complex model when you have a large number of features in a dataset are used Regularization techniques to address overfitting and feature selection.</p>

<p>As was said before, the regression model that use L1 Regularization technique is Lasso Regression and model which uses L2 Regularization technique is Ridge Regression. The key difference between these two is the penalty term.</p>

<p><strong>Ridge Regression</strong> adds “square magnitude” of coefficient as penalty term to the loss function. The second part of the formula bellow represents the L2 Regularization.</p>

\[\sum^n_{i=1}(y_i - \sum^p_{j=1}x_{ij}\Theta_j)^2 + \lambda\sum^p_{j=1}\Theta^2_j\]

<p>If the \(\lambda\) elemet is 0, then we will get back the ordinary least square, whereas a very large value it will add to much wieght and it will lead to underfit. Hence, it’s important how <em>lambda</em> is chosen. This technique works very well to avoid overfit issues.</p>

<p><strong>Lasso Regression</strong> adds <em>“absolute value of magnitude”</em> of coefficient as penalty term to the loss function.</p>

\[\sum^n_{i=1}(y_i - \sum^p_{j=1}x_{ij}\Theta_j)^2 + \lambda\sum^p_{j=1}|\Theta_j|\]

<p>Again, lambda zero it will get back de ordinary least square whereas very large value will make coefficients zero hence it will underfit.</p>

<p>The key different between this techniques is that Lasso shrinks the less important feature’s coefficient to zero thus, removing some feature altogether. So, this works well for <strong>feature selection</strong> in case we have a huge number of features.</p>

    <section class="related" style="margin-bottom: 5%;">
    
    
    
        
    
        
    
        
    
        
    
        
    
  </section>
    



<div class="post-tags">
  
    
    <a href="/machine-learning-algorithms-review/tags.html#supervised-learning">
    
      <span class="icon">
        <svg fill="#000000" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
    <path d="M0 0h24v24H0z" fill="none"/>
    <path d="M17.63 5.84C17.27 5.33 16.67 5 16 5L5 5.01C3.9 5.01 3 5.9 3 7v10c0 1.1.9 1.99 2 1.99L16 19c.67 0 1.27-.33 1.63-.84L22 12l-4.37-6.16z"/>
</svg>
      </span>&nbsp;<span class="tag-name">Supervised Learning</span>
    </a>
  
    
    <a href="/machine-learning-algorithms-review/tags.html#linear-models">
    
      <span class="icon">
        <svg fill="#000000" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
    <path d="M0 0h24v24H0z" fill="none"/>
    <path d="M17.63 5.84C17.27 5.33 16.67 5 16 5L5 5.01C3.9 5.01 3 5.9 3 7v10c0 1.1.9 1.99 2 1.99L16 19c.67 0 1.27-.33 1.63-.84L22 12l-4.37-6.16z"/>
</svg>
      </span>&nbsp;<span class="tag-name">Linear Models</span>
    </a>
  
    
    <a href="/machine-learning-algorithms-review/tags.html#regression">
    
      <span class="icon">
        <svg fill="#000000" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
    <path d="M0 0h24v24H0z" fill="none"/>
    <path d="M17.63 5.84C17.27 5.33 16.67 5 16 5L5 5.01C3.9 5.01 3 5.9 3 7v10c0 1.1.9 1.99 2 1.99L16 19c.67 0 1.27-.33 1.63-.84L22 12l-4.37-6.16z"/>
</svg>
      </span>&nbsp;<span class="tag-name">Regression</span>
    </a>
  
</div>
  </div>
  <section class="related">
  <h2>Related Posts</h2>
  <ul class="posts-list">
    
      <li>
        <h4>
          <a href="/machine-learning-algorithms-review/supervised%20learning/2021/05/11/Random-Forests.html">
            Random Forests
            <small>11 May 2021</small>
          </a>
        </h4>
      </li>
    
      <li>
        <h4>
          <a href="/machine-learning-algorithms-review/supervised%20learning/2021/05/11/Naive-Bayes-Classifiers.html">
            Naive Bayes Classifier
            <small>11 May 2021</small>
          </a>
        </h4>
      </li>
    
      <li>
        <h4>
          <a href="/machine-learning-algorithms-review/supervised%20learning/2021/05/11/Decision-Trees.html">
            Decision Trees
            <small>11 May 2021</small>
          </a>
        </h4>
      </li>
    
  </ul>
</section>

</div>

    </main>

    <!-- Optional footer content -->

  </body>
</html>
